{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a66f4b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c3d780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model\n",
      "Loading sets...\n",
      "Train and dev sets loaded\n",
      "Step 0 Loss 0.6735537455466525\n",
      "Step 1 Loss 0.6836371382493723\n",
      "Step 2 Loss 0.6925395727157593\n",
      "Step 3 Loss 0.9074100255966187\n",
      "Step 4 Loss 0.6778961620059204\n",
      "Step 5 Loss 0.6685147285461426\n",
      "Step 6 Loss 0.6735104322433472\n",
      "Step 7 Loss 0.6663330628612129\n",
      "Step 8 Loss 0.6785815954208374\n",
      "Step 9 Loss 0.6897897124290466\n",
      "Step 10 Loss 0.6447967290878296\n",
      "Step 11 Loss 0.6577913165092468\n",
      "Step 12 Loss 0.6219757199287415\n",
      "Step 13 Loss 0.6282685399055481\n",
      "Step 14 Loss 0.6634389162063599\n",
      "Step 15 Loss 0.7681278586387634\n",
      "Step 16 Loss 0.6670557360513306\n",
      "Step 17 Loss 0.5521855354509082\n",
      "Step 18 Loss 0.6398436427116394\n",
      "Step 19 Loss 0.6271913163292469\n",
      "Step 20 Loss 0.6171112461242562\n",
      "Start evaluation ...\n",
      "************* Evaluation ****************\n",
      "Step 20, Loss 0.6367923617362976   Accuracy 0.599756488439701\n",
      "              precision  recall    f1-score  support\n",
      "       Real       0.64      0.40      0.50        67\n",
      "       Fake       0.57      0.78      0.65        67\n",
      "[[27 40]\n",
      "[15 52]]\n",
      "*****************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import config\n",
    "import utils\n",
    "from model import DependencyBLSTM\n",
    "\n",
    "args = config.args\n",
    "output_dir = args.project_dir + 'Models/' + args.sim_name + '/'\n",
    "\n",
    "utils.creat_word_embedding()\n",
    "\n",
    "def run():\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    save_path = args.project_dir + 'Models/' + args.sim_name + '/model.pt'\n",
    "\n",
    "    with open(output_dir + 'config', 'w') as config_file:\n",
    "        argss = (str(args).split('(')[1].split(')')[0].split(','))\n",
    "        for a in argss:\n",
    "            config_file.write(\"{}\\n\".format(a))\n",
    "    if os.path.exists(save_path):\n",
    "        model = torch.load(save_path)\n",
    "        model_loaded = True\n",
    "        print('Great!!! Pre-Trained Model Loaded !!!')\n",
    "    else:\n",
    "        model_loaded = False\n",
    "        print('No pre-trained model ')\n",
    "        model = DependencyBLSTM(num_words=utils.get_num_words(), max_sen_length=97, max_doc_sent_length=326)\n",
    "\n",
    "    if not os.path.exists(output_dir + 'train_performance_log.csv'):\n",
    "        train_performance_log = open(output_dir + 'train_performance_log.csv', 'w')\n",
    "        train_performance_log.write('Step,Loss\\n')\n",
    "    else:\n",
    "        train_performance_log = open(output_dir + 'train_performance_log.csv', 'a')\n",
    "\n",
    "    if not os.path.exists(output_dir + 'eval_performance_log.txt'):\n",
    "        eval_performance_log = open(output_dir + 'eval_performance_log.txt', 'w')\n",
    "    else:\n",
    "        eval_performance_log = open(output_dir + 'eval_performance_log.txt', 'a')\n",
    "\n",
    "    if args.gpu > -1:\n",
    "        model.cuda(device=int(args.gpu))\n",
    "\n",
    "    if not model_loaded:\n",
    "        if args.fill_embedding:\n",
    "            embed = utils.get_word_embeddings(source='google')\n",
    "            if args.gpu > -1:\n",
    "                model.word_embedding.weight.data.set_(torch.FloatTensor((embed)).cuda(int(args.gpu)))\n",
    "            else:\n",
    "                model.word_embedding.weight.data.set_(torch.FloatTensor((embed)))\n",
    "        else:\n",
    "            if args.gpu > -1:\n",
    "                model.word_embedding.weight.data.set_(\n",
    "                    torch.FloatTensor((np.zeros((utils.get_num_words() + 1, args.word_dim)).astype())).cuda(\n",
    "                        int(args.gpu)))\n",
    "            else:\n",
    "                model.word_embedding.weight.data.set_(\n",
    "                    torch.FloatTensor((np.zeros((utils.get_num_words() + 1, args.word_dim))).astype(float)))\n",
    "\n",
    "    if args.train_embeddings == False:\n",
    "        model.word_embedding.weight.requires_grad = False\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=params, lr=args.lr, weight_decay=args.l2_coeff)\n",
    "    model.zero_grad()\n",
    "    scheduler = StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "    print('Loading sets...')\n",
    "    dev_set = utils.get_split_data(split='dev')\n",
    "    train_set = utils.get_split_data(split='train')\n",
    "    train_set =train_set[0:int(len(train_set)/2)]\n",
    "    print('Train and dev sets loaded')\n",
    "\n",
    "    def train():\n",
    "        prev_accuracy = 0\n",
    "        model.train()\n",
    "        for step in range(args.step_num + 1):\n",
    "            random.shuffle(train_set)\n",
    "            docs = train_set[0:args.batch_size]\n",
    "            labels = Variable(torch.LongTensor([d['label'] for d in docs]))\n",
    "            doc_encodings, _ = model(docs)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = doc_encodings.cpu()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            print(\"Step {} Loss {}\".format(step, loss.data))\n",
    "            train_performance_log.write(\"{},{}\\n\".format(step, loss.data))\n",
    "            if step % 20 == 0 and step:\n",
    "                accuracy = evaluation(step)\n",
    "                if accuracy >= prev_accuracy:\n",
    "                    torch.save(model, save_path)\n",
    "                    print(\"Best model saved in {} Accuracy {}\".format(save_path, accuracy))\n",
    "                    prev_accuracy = accuracy\n",
    "\n",
    "    def evaluation(step):\n",
    "        print('Start evaluation ...')\n",
    "        model.eval()\n",
    "        eval_labels = [d['label'] for d in dev_set]\n",
    "        labels = Variable(torch.LongTensor(eval_labels))\n",
    "        doc_encodings, _ = model(dev_set)\n",
    "        outputs = doc_encodings.cpu()\n",
    "        loss = criterion(outputs, labels).data\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        predictions = predictions.numpy()\n",
    "\n",
    "        accuracy = accuracy_score(y_true=np.array(eval_labels), y_pred=predictions)\n",
    "        report = classification_report(y_true=np.array(eval_labels), y_pred=predictions, target_names=['Real', 'Fake'])\n",
    "        conf_matrix = confusion_matrix(y_true=np.array(eval_labels), y_pred=predictions)\n",
    "        eval_performance_log.write(\"Step {}, Loss {} Accuracy {} \\n\".format(step, loss, accuracy))\n",
    "        eval_performance_log.write(\"{}\\n\".format(report))\n",
    "        eval_performance_log.write(\"{}\\n\".format(conf_matrix))\n",
    "        eval_performance_log.write(\"{}\\n\".format('=' * 50))\n",
    "\n",
    "        print('************* Evaluation ****************')\n",
    "        print(\"Step {}, Loss {}  Accuracy {} \".format(step, loss, accuracy))\n",
    "        print(report)\n",
    "        print(conf_matrix)\n",
    "        print('*****************************************')\n",
    "        return accuracy\n",
    "\n",
    "    train()\n",
    "\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
